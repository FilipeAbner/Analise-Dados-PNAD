# Pipeline ETL PNAD - ExtraÃ§Ã£o e VisualizaÃ§Ã£o

## VisÃ£o Geral

Este projeto demonstra a implementaÃ§Ã£o de um **pipeline ETL completo** para processamento de dados da **PNAD (Pesquisa Nacional por Amostra de DomicÃ­lios)** do IBGE, utilizando tecnologias modernas de engenharia de dados. A iniciativa foi desenvolvida como parte de um teste prÃ¡tico para atuaÃ§Ã£o no projeto 'Cajui Analytics'(software de anÃ¡lise de dados do IFNMG) e aprovado em **primeiro lugar**, demonstrando competÃªncias avanÃ§adas em:

- **Engenharia de Dados**: Pipeline ETL robusto e escalÃ¡vel
- **Modelagem Dimensional**: Design de data warehouse otimizado
- **Web Scraping**: AutomaÃ§Ã£o de coleta de dados
- **Business Intelligence**: VisualizaÃ§Ãµes interativas e dashboards
- **Arquitetura de Software**: CÃ³digo limpo, modular e bem documentado

## ğŸ¯ Objetivos AlcanÃ§ados

### ImplementaÃ§Ãµes Completas
- **Pipeline ETL End-to-End**: ExtraÃ§Ã£o, transformaÃ§Ã£o e carregamento automatizado
- **Modelagem Dimensional**: 5 dimensÃµes + 1 fato com relacionamentos otimizados
- **Web Scraping Inteligente**: Coleta automÃ¡tica de dados e dicionÃ¡rios do IBGE
- **Tratamento de Dados**: NormalizaÃ§Ã£o, limpeza e validaÃ§Ã£o robusta
- **Cache Inteligente**: OtimizaÃ§Ã£o de performance com cache de dimensÃµes
- **Arquitetura Modular**: CÃ³digo organizado e reutilizÃ¡vel

### ğŸ¨ Dashboards e VisualizaÃ§Ãµes
- **Knowage BI**: Plataforma de Business Intelligence integrada
- **GrÃ¡ficos Interativos**: VisualizaÃ§Ãµes HTML/CSS/JavaScript customizadas
- **AnÃ¡lises Multidimensionais**: Insights sobre trabalho, educaÃ§Ã£o e demografia

> **Nota**: Devido Ã s limitaÃ§Ãµes da ferramenta Knowage BI para exportaÃ§Ã£o de cockpits, todos os grÃ¡ficos foram implementados como custom charts(HTML, CSS, JavaScript) e estÃ£o disponÃ­veis em [Dashboard](dashboard/).

## ğŸ—ï¸ Arquitetura do Sistema

### Estrutura do Projeto
```
projeto/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â”œâ”€â”€ mapper.py           # Mapeamento inteligente de colunas
â”‚   â”‚   â”œâ”€â”€ webScrapping.py     # Coleta automatizada de dados
â”‚   â”‚   â”œâ”€â”€ extract.py          # ExtraÃ§Ã£o otimizada de dados
â”‚   â”‚   â”œâ”€â”€ etl.py             # Pipeline ETL principal
â”‚   â”‚   â””â”€â”€ transform/         # MÃ³dulos de transformaÃ§Ã£o
â”‚   â”‚       â”œâ”€â”€ tratar_campos_texto.py
â”‚   â”‚       â”œâ”€â”€ tratar_educacao.py
â”‚   â”‚       â””â”€â”€ tratar_fato_trabalho_pessoa.py
â”‚   â”œâ”€â”€ util/
â”‚   â”‚   â”œâ”€â”€ data_pattern.py    # UtilitÃ¡rios de tratamento de texto
â”‚   â”‚   â””â”€â”€ orm_utils.py       # UtilitÃ¡rios ORM
â”‚   â”œâ”€â”€ connection.py          # ConfiguraÃ§Ã£o de conexÃ£o
â”‚   â””â”€â”€ dimensional_models.py  # Modelos dimensionais SQLAlchemy
â”œâ”€â”€ data/                     # Dados que seÃ£o processados e dump
â”‚   â””â”€â”€ dump/
â”‚       â””â”€â”€ dump.backup       # dados processados
â”œâ”€â”€ dashboard/              # CÃ³digo dos grÃ¡ficos interativos
â”‚   â”œâ”€â”€ graficoLinhas/
â”‚   â”‚   â”œâ”€â”€ GL_css.css
â”‚   â”‚   â””â”€â”€ GL_html.html
â”‚   â”‚   â””â”€â”€ GL_javascript.js
â”‚   â”œâ”€â”€ slices/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ README.md
â”œâ”€â”€ Dicionario_dados.md     # dicionario das variaveis e as descriÃ§Ãµes das variaveis
â”œâ”€â”€ ERD.png                 # diagrama de entidade relacionamento
â””â”€â”€ requirements.txt        # DependÃªncias do projeto
```

## ğŸ“Š Modelagem Dimensional

### Modelos Dimensionais
- **Educacao**: DimensÃ£o de educaÃ§Ã£o (tipo_escola_desc, nivel_instrucao_max_desc, anos_estudo, frequenta_escola_desc, sabe_ler_escrever_desc)
- **Regiao**: DimensÃ£o geogrÃ¡fica (nome_uf_desc, area_desc, situacao_domicilio_desc)
- **Individuo**: DimensÃ£o de caracterÃ­sticas individuais (sexo_desc, idade, cor_raca_desc, nmr_pessoas_domicilio)
- **Tempo**: DimensÃ£o temporal (ano, trimestre)
- **Trabalho**: DimensÃ£o de trabalho (condicao_ocupacao_desc, posicao_ocupacao_trabalho_principal_desc, atividade_principal_desc)
- **Fato_Trabalho_pessoa**: Tabela de fatos relacionando todas as dimensÃµes

### Pipeline ETL - TÃ©cnico

O processo de ETL comeÃ§a no arquivo etl.py, que Ã© o arquivo principal do projeto. Nele Ã© definido o ano que serÃ¡ processado e aplicado o web scraping(webScrapping.py) para obter o dicionario das variaveis e os microdados da PNAD(os dados sÃ£o salvos no diretorio data), Ã© realizada uma junÃ§Ã£o automatica das colunas do dicionario com as colunas do microdados para obter a descriÃ§Ã£o correta das variaveis, o arquivo mapper.py Ã© responsÃ¡vel por mapear as colunas do dicionario com as colunas do microdados. ApÃ³s isso, o arquivo extract.py Ã© responsÃ¡vel por ler os dados do arquivo sas e transforma-los em um DataFrame. O diretÃ³rio transform/ contem os scripts que tratam os dados e retornam o DataFrame tratado. Por fim, o controle retorna ao arquivo etl.py que Ã© responsÃ¡vel por carregar os dados no banco de dados de acordo com o modelo definido no arquivo dimensional_models.py via ORM com SQLAlchemy.

## Funcionalidades Adicionais

- âœ… Coleta automÃ¡tica de microdados trimestrais
- âœ… Download e descompactaÃ§Ã£o de arquivos ZIP
- âœ… Mapeamento inteligente de dicionÃ¡rios
- âœ… Tratamento de erros robusto(NormalizaÃ§Ã£o de texto, remoÃ§Ã£o de acentos, uppercase,etc)

## ğŸ“Š GrÃ¡ficos e VisualizaÃ§Ãµes

### ğŸ¨ Dashboard Implementado
![Dash1](images/dashboard1.png)
![Dash2](images/dashboard2.png)
![Dash3](images/dashboard3.png)


### ğŸ“ˆ AnÃ¡lises DisponÃ­veis

1. **DistribuiÃ§Ã£o DemogrÃ¡fica**
   - Perfil por idade, gÃªnero e regiÃ£o
   - AnÃ¡lise de cor/raÃ§a por estado

2. **Indicadores Educacionais**
   - NÃ­vel de instruÃ§Ã£o por regiÃ£o
   - Anos de estudo por faixa etÃ¡ria
   - FrequÃªncia escolar

3. **MÃ©tricas de Trabalho**
   - Renda mÃ©dia por ocupaÃ§Ã£o
   - Horas trabalhadas por setor
   - DistribuiÃ§Ã£o por posiÃ§Ã£o na ocupaÃ§Ã£o

4. **AnÃ¡lises Multidimensionais**
   - CorrelaÃ§Ã£o entre educaÃ§Ã£o e renda
   - DiferenÃ§as regionais no mercado de trabalho
   - EvoluÃ§Ã£o temporal dos indicadores

### ğŸ¬ DemonstraÃ§Ã£o em VÃ­deo

**Link para demonstraÃ§Ã£o completa do dashboard:** https://youtu.be/_xLaru0XOsI

> **[ESPAÃ‡O RESERVADO PARA GIFS DOS GRÃFICOS EM AÃ‡ÃƒO]**
> 
> *Aqui serÃ£o inseridos GIFs mostrando a interatividade dos dashboards*

## ğŸ› ï¸ Tecnologias Utilizadas

### Backend
- **Python 3.12.3**: Linguagem principal
- **SQLAlchemy**: ORM para modelagem dimensional
- **Pandas**: ManipulaÃ§Ã£o e transformaÃ§Ã£o de dados
- **Requests**: Web scraping e APIs

### Frontend (Dashboards)
- **HTML5/CSS3**: Estrutura e estilizaÃ§Ã£o
- **JavaScript**: Interatividade e animaÃ§Ãµes
- **Knowage BI**: Plataforma de Business Intelligence

### Banco de Dados
- **PostgreSQL**: Banco de dados relacional
- **Modelagem Dimensional**: Star Schema 

## ğŸš€ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### PrÃ©-requisitos
- Python 3.12.3+
- PostgreSQL

### 1. Clone e Configure
```bash
git clone <repository-url>
cd projeto
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows
```

### 2. Instale DependÃªncias
```bash
pip install -r requirements.txt
```

### 3. Configure o Banco de Dados
```bash
# Crie o arquivo .env baseado no .envexample
cp .envexample .env

# Configure as credenciais no .env
# Crie o banco de dados com esquema 'dimensional'
```

### 4. Execute o Pipeline
```bash
python .
```

## ğŸ“ˆ OtimizaÃ§Ãµes

### OtimizaÃ§Ãµes Implementadas
- âœ… **Cache Inteligente**: Evita reprocessamento de dimensÃµes
- âœ… **Processamento em Lotes**: Reduz uso de memÃ³ria
- âœ… **Ãndices Otimizados**: Consultas rÃ¡pidas no banco
- âœ… **TransaÃ§Ãµes Eficientes**: Commit em lotes

## ğŸ¯ Diferenciais do Projeto

### 1. **AutomaÃ§Ã£o Completa**
- Web scraping automatizado do IBGE
- Mapeamento inteligente de dicionÃ¡rios
- Pipeline end-to-end sem intervenÃ§Ã£o manual

### 2. **Arquitetura EscalÃ¡vel**
- CÃ³digo modular e reutilizÃ¡vel
- SeparaÃ§Ã£o clara de responsabilidades
- FÃ¡cil manutenÃ§Ã£o e extensÃ£o

### 3. **Qualidade de Dados**
- ValidaÃ§Ã£o robusta em todas as etapas
- Tratamento inteligente de valores nulos
- NormalizaÃ§Ã£o consistente de dados

### 4. **Performance Otimizada**
- Cache de dimensÃµes
- Processamento em lotes
- Consultas otimizadas

## ğŸ“š DocumentaÃ§Ã£o Adicional

- **DicionÃ¡rio de Dados**: `Dicionario_dados.md`
- **Diagrama ER**: `ERD.png`
- **DemonstraÃ§Ã£o**: [VÃ­deo no YouTube](https://youtu.be/_xLaru0XOsI)

## ğŸ† ConclusÃ£o

Este projeto representou um grande desafio, nÃ£o apenas relacioando a competÃªncias tÃ©cnicas, mas tambÃ©m a capacidade de entregar soluÃ§Ãµes completas e funcionais dentro de prazos curtos. AlÃ©m da aprovaÃ§Ã£o o teste prÃ¡tico serviu como uma importante validaÃ§Ã£o das minhas habilidades em engenharia de dados, a partir deste teste puder perceber que qualidade tÃ©cnica e capacidade de entrega sÃ£o igualmente importantes e Ã© necessario realizar um planejamento para que ambas sejam compridas com Ãªxito. Mesmo com limitaÃ§Ãµes de tempo, desde o comeÃ§o decidi fazer um gerenciamento das principais atividades que deveriam ser entregues e direcionar meus esforÃ§os nas informaÃ§Ãµes mais importantes, isso me permitiu desenvolver uma soluÃ§Ã£o que permite visualizar, analisar e explorar os dados da PNAD ContÃ­nua de forma clara, flexÃ­vel e acessÃ­vel, facilitando a geraÃ§Ã£o de insights relevantes para a tomada de decisÃ£o.

## ğŸ¤ ContribuiÃ§Ãµes e Melhorias Futuras

- [ ] Suporte a mÃºltiplos anos de dados
- [ ] Machine Learning para prediÃ§Ãµes
- [ ] Mais visualizaÃ§Ãµes interativas
- [ ] IntegraÃ§Ã£o com outras fontes de dados

## ğŸ“ Contato

Para dÃºvidas sobre o projeto ou oportunidades de colaboraÃ§Ã£o:

- **LinkedIn**: [https://www.linkedin.com/in/filipeabner18/]
- **Email**: [filipeabner18@gmail.com]
- **GitHub**: [https://github.com/FilipeAbner]

